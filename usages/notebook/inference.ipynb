{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T04:48:05.445192Z",
     "start_time": "2024-12-30T04:48:04.412132Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import stackview\n",
    "import datetime\n",
    "\n",
    "import ailoc.lunar\n",
    "import ailoc.deeploc\n",
    "import ailoc.common\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "ailoc.common.setup_seed(42)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set the paths of DeepLoc model, images, predictions and analyzer parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T04:48:07.230121Z",
     "start_time": "2024-12-30T04:48:07.206901Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73cb159817f34deeae8dff7f985dae9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectFilesButton(description='Select trained model', icon='square-o', layout=Layout(height='80px', width='100…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9adedd159144da38fcdb4dcb238a565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Select all tiff files under the folder', indent=False)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e60ab89a4c4fd98555df60987631fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectFilesButton(description='Select tiff file', icon='square-o', layout=Layout(height='80px', width='100%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcd87b0be1a4609b5549ac928f91d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SaveFilesButton(description='Save predicted CSV', icon='square-o', layout=Layout(height='80px', width='100%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f2894be96f4513b4e763de2c8be466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridspecLayout(children=(BoundedIntText(value=1, description='Block(GB)', layout=Layout(grid_area='widget001')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6561d6effe433f8d2cd05259b1c485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='OK', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691acbfaba0840dd8bcea372faa51aa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyzer_param_widget = ailoc.common.SetAnalyzerParamWidget()\n",
    "analyzer_param_widget.display_notebook_gui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run the code cell to initialize the DeepLoc analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-30T04:48:12.213675Z",
     "start_time": "2024-12-30T04:48:12.176615Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "the file to save the predictions is: E:/projects/FS_work/AI4Loc_FS/AI4Loc/results/2024-12-30-13LUNAR_SL_demo2-exp_npc_dmo1_predictions.csv\n",
      "frame ranges || filename: \n",
      "[0-26675] || E:\\projects\\FS_work\\AI4Loc_FS\\AI4Loc\\datasets\\demo2-exp_npc_dmo1.2\\npc_DMO1.2__6_MMStack_Default.ome.tif\n",
      "[26676-53351] || E:\\projects\\FS_work\\AI4Loc_FS\\AI4Loc\\datasets\\demo2-exp_npc_dmo1.2\\npc_DMO1.2__6_MMStack_Default_1.ome.tif\n",
      "[53352-79300] || E:\\projects\\FS_work\\AI4Loc_FS\\AI4Loc\\datasets\\demo2-exp_npc_dmo1.2\\npc_DMO1.2__6_MMStack_Default_2.ome.tif\n",
      "\u001b[0;31mWarning: meta data shows that the tiff stack has 100000 frames, the sum of all file pages is 79301\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_analyzer = ailoc.common.SmlmDataAnalyzer(loc_model=analyzer_param_widget.analyzer_param['loc_model'],\n",
    "                                                 tiff_path=analyzer_param_widget.analyzer_param['tiff_path'],\n",
    "                                                 output_path=analyzer_param_widget.analyzer_param['output_path'],\n",
    "                                                 time_block_gb=analyzer_param_widget.analyzer_param['time_block_gb'],\n",
    "                                                 batch_size=analyzer_param_widget.analyzer_param['batch_size'],\n",
    "                                                 sub_fov_size=analyzer_param_widget.analyzer_param['sub_fov_size'],\n",
    "                                                 over_cut=analyzer_param_widget.analyzer_param['over_cut'],\n",
    "                                                 num_workers=analyzer_param_widget.analyzer_param['num_workers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Check the predictions about a specific frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e3bbdf5b76478c856a123cec34d945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Label(value='Input the frame number:'), BoundedIntText(value=0, max=79300))), Ou…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame_num_widget = widgets.HBox([widgets.Label(value='Input the frame number:'), widgets.BoundedIntText(value=0, min=0, max=data_analyzer.tiff_dataset.sum_file_length-1, step=1,)])\n",
    "out = widgets.interactive_output(data_analyzer.check_single_frame_output, {'frame_num': frame_num_widget.children[1]})\n",
    "\n",
    "display(widgets.VBox([frame_num_widget, out]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the code cell to analyze the data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing block: 1/11, contain frames: 7589, already analyzed: 0/79301, ETA: inf min\n",
      "\r",
      "Processing sub-FOV: 1/4, (0, 263, 0, 263), keep molecules in: (0, 255, 0, 255), loc model: <class 'ailoc.lunar.lunar.Lunar_SyncLearning'>"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preds_array, preds_rescale_array \u001b[38;5;241m=\u001b[39m \u001b[43mdata_analyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivide_and_conquer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\projects\\FS_work\\AI4Loc_FS\\AI4Loc\\usages\\notebook\\../..\\ailoc\\common\\analyzer.py:500\u001b[0m, in \u001b[0;36mSmlmDataAnalyzer.divide_and_conquer\u001b[1;34m(self, degrid)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mui_print_signal\u001b[38;5;241m.\u001b[39memit(print_message_tmp) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mui_print_signal \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[1;32m--> 500\u001b[0m     molecule_list_tmp, inference_dict_tmp \u001b[38;5;241m=\u001b[39m \u001b[43mdata_analyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_fov_data_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi_fov\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43msub_fov_xy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msub_fov_xy_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi_fov\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mcamera\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamera\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mretain_infer_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m sub_fov_molecule_list\u001b[38;5;241m.\u001b[39mappend(molecule_list_tmp)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# del molecule_list_tmp, inference_dict_tmp\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n",
      "File \u001b[1;32mE:\\projects\\FS_work\\AI4Loc_FS\\AI4Loc\\usages\\notebook\\../..\\ailoc\\common\\analyzer.py:78\u001b[0m, in \u001b[0;36mdata_analyze\u001b[1;34m(loc_model, data, sub_fov_xy, camera, batch_size, retain_infer_map)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(num_img \u001b[38;5;241m/\u001b[39m batch_size))):\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rolling_inference:\n\u001b[1;32m---> 78\u001b[0m         molecule_array_tmp, inference_dict_tmp \u001b[38;5;241m=\u001b[39m \u001b[43mloc_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[43mailoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mextra_length\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcamera\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m            \u001b[49m\u001b[43msub_fov_xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretain_infer_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m         molecule_array_tmp, inference_dict_tmp \u001b[38;5;241m=\u001b[39m loc_model\u001b[38;5;241m.\u001b[39manalyze(\n\u001b[0;32m     85\u001b[0m             ailoc\u001b[38;5;241m.\u001b[39mcommon\u001b[38;5;241m.\u001b[39mgpu(data[i \u001b[38;5;241m*\u001b[39m batch_size: (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size]),\n\u001b[0;32m     86\u001b[0m             camera,\n\u001b[0;32m     87\u001b[0m             sub_fov_xy,\n\u001b[0;32m     88\u001b[0m             retain_infer_map)\n",
      "File \u001b[1;32mE:\\projects\\FS_work\\AI4Loc_FS\\AI4Loc\\usages\\notebook\\../..\\ailoc\\lunar\\lunar.py:232\u001b[0m, in \u001b[0;36mLunar_LocLearning.analyze\u001b[1;34m(self, data, camera, sub_fov_xy, return_infer_map)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 232\u001b[0m     p_pred, xyzph_pred, xyzph_sig_pred, bg_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     molecule_array, inference_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_process(p_pred,\n\u001b[0;32m    234\u001b[0m                                                        xyzph_pred,\n\u001b[0;32m    235\u001b[0m                                                        xyzph_sig_pred,\n\u001b[0;32m    236\u001b[0m                                                        bg_pred,\n\u001b[0;32m    237\u001b[0m                                                        return_infer_map)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m molecule_array, inference_dict\n",
      "File \u001b[1;32mE:\\projects\\FS_work\\AI4Loc_FS\\AI4Loc\\usages\\notebook\\../..\\ailoc\\lunar\\lunar.py:186\u001b[0m, in \u001b[0;36mLunar_LocLearning.inference\u001b[1;34m(self, data, camera)\u001b[0m\n\u001b[0;32m    184\u001b[0m data_photon \u001b[38;5;241m=\u001b[39m camera\u001b[38;5;241m.\u001b[39mbackward(data)\n\u001b[0;32m    185\u001b[0m data_scaled \u001b[38;5;241m=\u001b[39m (data_photon \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_ph_offset)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_ph_factor\n\u001b[1;32m--> 186\u001b[0m p_pred, xyzph_pred, xyzph_sig_pred, bg_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_scaled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p_pred, xyzph_pred, xyzph_sig_pred, bg_pred\n",
      "File \u001b[1;32mD:\\Softwares\\anaconda3\\envs\\ailoc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Softwares\\anaconda3\\envs\\ailoc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mE:\\projects\\FS_work\\AI4Loc_FS\\AI4Loc\\usages\\notebook\\../..\\ailoc\\lunar\\network.py:330\u001b[0m, in \u001b[0;36mLunarNet.forward\u001b[1;34m(self, x_input)\u001b[0m\n\u001b[0;32m    325\u001b[0m fem_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfem_norm(fem_out)\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemporal_attn:\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;66;03m# transformer based tam, since each traning/analysis batch is padded with attn_length//2 frames\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;66;03m# at the beginning and end, we only need the prediction of the middle frames\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m     tam_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfem_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    332\u001b[0m         tam_out \u001b[38;5;241m=\u001b[39m tam_out[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m: \u001b[38;5;241m-\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_length\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)]\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features, img_h, img_w])\n",
      "File \u001b[1;32mD:\\Softwares\\anaconda3\\envs\\ailoc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Softwares\\anaconda3\\envs\\ailoc\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mE:\\projects\\FS_work\\AI4Loc_FS\\AI4Loc\\usages\\notebook\\../..\\ailoc\\lunar\\transformer.py:417\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    415\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslayer(x, attn_mask)\n\u001b[0;32m    416\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_layer\u001b[38;5;241m.\u001b[39mbackward(x)\n\u001b[1;32m--> 417\u001b[0m context_dropout_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_dropout(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_dropout\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m    419\u001b[0m     context_dropout_mask \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_dropout_rate)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preds_array, preds_rescale_array = data_analyzer.divide_and_conquer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
